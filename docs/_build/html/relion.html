<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Relion &mdash; tem-docs 1.0 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/my_theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="cisTEM" href="cisTEM.html" />
    <link rel="prev" title="Batch Queues" href="queue.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            tem-docs
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="changelog.html">Change Logs</a></li>
<li class="toctree-l1"><a class="reference internal" href="newfarm.html">GSDC Computing Cluster for TEM</a><ul>
<li class="toctree-l2"><a class="reference internal" href="newfarm.html#service-overview">1. Service overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="newfarm.html#computing-and-storage-resources">2. Computing and storage resources</a></li>
<li class="toctree-l2"><a class="reference internal" href="newfarm.html#cluster-management-softwares">3. Cluster management softwares</a></li>
<li class="toctree-l2"><a class="reference internal" href="newfarm.html#data-analysis-tools">4. Data analysis tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="newfarm.html#requesting-user-accounts-and-accessing-gsdc-tem-computing-cluster">5. Requesting user accounts and accessing GSDC TEM computing cluster</a></li>
<li class="toctree-l2"><a class="reference internal" href="newfarm.html#module-paths-and-job-submission-templates">6. Module paths and job submission templates</a><ul>
<li class="toctree-l3"><a class="reference internal" href="newfarm.html#module-paths-for-data-analysis-tools">Module paths for data analysis tools</a></li>
<li class="toctree-l3"><a class="reference internal" href="newfarm.html#job-submission-templates">Job submission templates</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="newfarm.html#batch-queues">7. Batch queues</a><ul>
<li class="toctree-l3"><a class="reference internal" href="newfarm.html#checking-batch-queue-names-and-their-status">Checking batch queue names and their status</a></li>
<li class="toctree-l3"><a class="reference internal" href="newfarm.html#checking-all-worker-nodes-status">Checking all worker nodes status</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="newfarm.html#fstat-bin-monitoring-the-usage-of-all-the-worker-nodes">8. fstat.bin : Monitoring the usage of all the worker nodes</a></li>
<li class="toctree-l2"><a class="reference internal" href="newfarm.html#dynmotd-checking-storage-quota-limit-and-usage-ratio">9. dynmotd : Checking storage quota limit and usage ratio</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="guide.html">TEM Computing Cluster Basics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="guide.html#requesting-accounts-and-accessing-tem-cluster">Requesting accounts and accessing TEM cluster</a><ul>
<li class="toctree-l3"><a class="reference internal" href="guide.html#for-linux-mac-users">For Linux/Mac users</a></li>
<li class="toctree-l3"><a class="reference internal" href="guide.html#for-windows-users">For Windows users</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="guide.html#understanding-environment-modules">Understanding environment modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="guide.html#job-manager-torque">Job manager (Torque)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="guide.html#resources-manager-and-job-scheduler">Resources manager and job scheduler</a></li>
<li class="toctree-l3"><a class="reference internal" href="guide.html#directives-in-torque-job-scripts">Directives in Torque job scripts</a><ul>
<li class="toctree-l4"><a class="reference internal" href="guide.html#resource-limits"><strong>Resource limits</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="guide.html#job-name"><strong>Job name</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="guide.html#queue-name"><strong>Queue name</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="guide.html#job-log-files"><strong>Job log files</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="guide.html#torque-job-script-examples">Torque job script examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="guide.html#simple-sequential-job"><strong>Simple sequential job</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="guide.html#serial-job-with-openmp-multithreading"><strong>Serial job with OpenMP multithreading</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="guide.html#simple-mpi-parallel-job"><strong>Simple MPI parallel job</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="guide.html#parallel-job-with-mpi-and-openmp"><strong>Parallel job with MPI and OpenMP</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="guide.html#job-submission">Job submission</a></li>
<li class="toctree-l3"><a class="reference internal" href="guide.html#monitoring-and-managing-your-jobs">Monitoring and managing your jobs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="guide.html#status-of-queued-jobs"><strong>Status of queued jobs</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="guide.html#managing-your-jobs"><strong>Managing your jobs</strong></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="queue.html">Batch Queues</a><ul>
<li class="toctree-l2"><a class="reference internal" href="queue.html#batch-queue-list">Batch queue list</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Relion</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#executing-relion-gui-tools">Executing Relion GUI tools</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#how-to-start-relion-data-analysis-tool">How to start Relion data analysis tool</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#pbs-strings-used-in-relion">PBS Strings used in Relion</a></li>
<li class="toctree-l2"><a class="reference internal" href="#running-data-analysis-jobs-using-cpu-cores">Running data analysis jobs using CPU cores</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#module-path">Module path</a></li>
<li class="toctree-l3"><a class="reference internal" href="#environment-variables">Environment variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="#standard-job-submission-script-for-relion-4-0-0-cpu-use">Standard job submission script (for relion 4.0.0 CPU use)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#running-data-analysis-jobs-using-gpgpus">Running data analysis jobs using GPGPUs</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">Environment variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="#standard-job-submission-script-for-relion-4-0-0-gpgpu-use">Standard job submission script (for relion 4.0.0 GPGPU use)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#specifying-which-gpgpus-to-use">Specifying which GPGPUs to use</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#examples">Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#motion-correction">Motion Correction</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ctf-estimation">CTF Estimation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#d-classification">2D Classification</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cisTEM.html">cisTEM</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cisTEM.html#executing-cistem">Executing cisTEM</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cisTEM.html#how-to-start-cistem-data-analysis-tool">How to start cisTEM data analysis tool</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cisTEM.html#run-profiles-for-job-submission">Run profiles for job submission</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cisTEM.html#profile-templates">Profile templates</a></li>
<li class="toctree-l3"><a class="reference internal" href="cisTEM.html#adding-a-new-run-profile">Adding a new Run Profile</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cisTEM.html#examples-of-running-cistem-jobs">Examples of running cisTEM jobs</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cisTEM.html#importing-movies-and-images">Importing Movies and images</a></li>
<li class="toctree-l3"><a class="reference internal" href="cisTEM.html#movie-alignment">Movie Alignment</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cryoSPARC.html">CryoSPARC</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cryoSPARC.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l2"><a class="reference internal" href="cryoSPARC.html#getting-a-cryosparc-instance">Getting a cryoSPARC instance</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cryoSPARC.html#admin-install-and-setup-a-cryosparc-instance">1. (Admin) Install and setup a cryoSPARC instance</a></li>
<li class="toctree-l3"><a class="reference internal" href="cryoSPARC.html#user-verifying-installation">2. (User) Verifying installation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cryoSPARC.html#launching-cryosparc-instance">Launching CryoSPARC instance</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cryoSPARC.html#for-linux-mac-users">For Linux/Mac users</a></li>
<li class="toctree-l3"><a class="reference internal" href="cryoSPARC.html#for-windows-users">For Windows users</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cryoSPARC.html#exploring-cryosparc-web-apps">Exploring CryoSPARC web apps</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cryoSPARC.html#cryosparc-login">CryoSPARC login</a></li>
<li class="toctree-l3"><a class="reference internal" href="cryoSPARC.html#cryosparc-dashboard">CryoSPARC dashboard</a></li>
<li class="toctree-l3"><a class="reference internal" href="cryoSPARC.html#cryosparc-project">CryoSPARC project</a></li>
<li class="toctree-l3"><a class="reference internal" href="cryoSPARC.html#cryosparc-cluster-lane">CryoSPARC cluster(lane)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cryoSPARC.html#tutorial-on-processing-t20s">Tutorial on processing T20S</a></li>
<li class="toctree-l2"><a class="reference internal" href="cryoSPARC.html#trouble-shooting">Trouble shooting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cryoSPARC.html#how-to-stop-or-start-the-cryosparc-instance">1. How to stop or start the cryoSPARC instance?</a></li>
<li class="toctree-l3"><a class="reference internal" href="cryoSPARC.html#how-to-reset-the-password-of-non-admin-user">2. How to reset the password of non-admin user?</a></li>
<li class="toctree-l3"><a class="reference internal" href="cryoSPARC.html#job-or-workflow-failed-caused-by-ssd-caching">3. Job (or Workflow) failed caused by <strong>SSD caching</strong></a></li>
<li class="toctree-l3"><a class="reference internal" href="cryoSPARC.html#failed-to-launch-190">4. Failed to launch! 190</a></li>
<li class="toctree-l3"><a class="reference internal" href="cryoSPARC.html#binary-locations-of-gctf-motioncor2">5. Binary locations of Gctf, MotionCor2</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topaz.html">Topaz</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topaz.html#topaz-executables">Topaz Executables</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topaz.html#topaz-binary-executable-with-cuda-9-2">Topaz binary executable with CUDA 9.2</a></li>
<li class="toctree-l3"><a class="reference internal" href="topaz.html#topaz-binary-executable-with-cuda-11-2">Topaz binary executable with CUDA 11.2</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topaz.html#using-topaz-in-cryosparc">Using Topaz in CryoSPARC</a></li>
<li class="toctree-l2"><a class="reference internal" href="topaz.html#using-topaz-in-relion-v3-1-0-above">Using Topaz in Relion (v3.1.0 above)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQs</a><ul>
<li class="toctree-l2"><a class="reference internal" href="faq.html#how-to-resolve-the-problems-on-re-starting-your-own-cryosparc-instance">How to resolve the problems on (re)starting your own cryosparc instance?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#how-to-repair-cryosparc-database-corruption">How to repair cryosparc database corruption?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#how-to-upgrade-or-downgrade-to-the-specific-version-of-cryosparc-softwares">How to upgrade (or downgrade) to the specific version of cryosparc softwares?</a><ul>
<li class="toctree-l3"><a class="reference internal" href="faq.html#checking-for-updates">1. Checking for updates</a></li>
<li class="toctree-l3"><a class="reference internal" href="faq.html#before-you-update-complete-or-kill-running-jobs">2. Before you update: complete or kill running jobs</a></li>
<li class="toctree-l3"><a class="reference internal" href="faq.html#back-up-cryosparc-databases">3. Back-up cryosparc databases</a></li>
<li class="toctree-l3"><a class="reference internal" href="faq.html#cryosparc-master-updates">4. Cryosparc master updates</a></li>
<li class="toctree-l3"><a class="reference internal" href="faq.html#cryosparc-worker-updates">5. Cryosparc worker updates</a></li>
<li class="toctree-l3"><a class="reference internal" href="faq.html#running-the-newer-cryosparc-instance">6. Running the newer cryosparc instance</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="app.html">APPENDIX : Application Form &amp; Materials </a><ul>
<li class="toctree-l2"><a class="reference internal" href="app.html#gsdc-tem-application-form">GSDC TEM Application Form</a></li>
<li class="toctree-l2"><a class="reference internal" href="app.html#tutorial">Tutorial</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="contact.html">Contacts</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">tem-docs</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Relion</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/relion.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="relion">
<h1>Relion<a class="headerlink" href="#relion" title="Permalink to this heading"></a></h1>
<p>RELION (for REgularised LIkelihood OptimisatioN, pronounce rely-on) is a stand-alone computer program that employs an empirical Bayesian approach to refinement of (multiple) 3D reconstructions or 2D class averages in electron cryo-microscopy (cryo-EM). (from Relion official site <a class="reference external" href="https://www3.mrc-lmb.cam.ac.uk/relion/index.php?title=Main_Page">https://www3.mrc-lmb.cam.ac.uk/relion/index.php?title=Main_Page</a>)</p>
<section id="executing-relion-gui-tools">
<h2>Executing Relion GUI tools<a class="headerlink" href="#executing-relion-gui-tools" title="Permalink to this heading"></a></h2>
<section id="how-to-start-relion-data-analysis-tool">
<h3>How to start Relion data analysis tool<a class="headerlink" href="#how-to-start-relion-data-analysis-tool" title="Permalink to this heading"></a></h3>
<ol class="arabic simple">
<li><p>You can find out relion applications’ environment module path by listing all the module available on TEM service farm</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$&gt;<span class="w"> </span>module<span class="w"> </span>avail

--------<span class="w"> </span>/tem/el7/Modules/apps<span class="w"> </span>--------
apps/cistem/1.0.0
apps/relion/cpu/3.0.7
apps/relion/cpu/3.1.0
apps/relion/cpu/4.0.0
apps/relion/gpu/3.0.7
apps/relion/gpu/3.1.0
apps/relion/gpu/4.0.0

----<span class="w"> </span>/tem/el7/Modules/acceleration<span class="w"> </span>----
cuda/9.2<span class="w">  </span>cuda/11.2

--------<span class="w"> </span>/tem/el7/Modules/mpi<span class="w"> </span>---------
mpi/gcc/4.8.5/openmpi/4.0.3
mpi/gcc/8.3.1/mpich/3.4.3
mpi/gcc/8.3.1/openmpi/4.0.3
mpi/gcc/openmpi/4.0.3

-----<span class="w"> </span>/tem/el7/Modules/virtualenv<span class="w"> </span>-----
conda/2020.11<span class="w">  </span>topaz/cuda-9.2/0.2.4
pyem/0.5<span class="w">       </span>topaz/cuda-11.0/0.2.4

-------<span class="w"> </span>/tem/el7/Modules/tools<span class="w"> </span>--------
tools/aspera-cli/3.9.6
tools/ctffind/4.1.14
tools/gctf/1.18_b2
tools/motioncor2/1.3.1
tools/resmap/1.1.4
tools/summovie/1.0.2
tools/unblur/1.0.2

-----<span class="w"> </span>/tem/el7/Modules/experiment<span class="w"> </span>-----
PyRosetta/4
python/3.7
rosetta/mpich-3.4.3/3.13
rosetta/openmpi-4.0.3/3.13
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>Check the module details for the specific relion version (e.g., Relion v4.0.0 with GPGPU support or Relion v4.0.0 with CPU cores support only)</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$&gt;<span class="w"> </span>module<span class="w"> </span>show<span class="w"> </span>apps/relion/gpu/4.0.0

-------------------------------------------------------------------
/tem/el7/Modules/apps/apps/relion/gpu/4.0.0:

module-whatis<span class="w">   </span><span class="o">{</span>Setups<span class="w"> </span>relion<span class="w"> </span><span class="m">4</span>.0.0<span class="w"> </span>environment<span class="w"> </span>variables<span class="o">}</span>
module<span class="w">          </span>load<span class="w"> </span>mpi/gcc/openmpi/4.0.3
module<span class="w">          </span>load<span class="w"> </span>cuda/11.2
setenv<span class="w">          </span>relion_version<span class="w"> </span><span class="m">4</span>.0.0
prepend-path<span class="w">    </span>PATH<span class="w"> </span>/tem/el7/relion-4.0.0/gpu/bin
prepend-path<span class="w">    </span>LD_LIBRARY_PATH<span class="w"> </span>/tem/el7/relion-4.0.0/gpu/lib
setenv<span class="w">          </span>LANG<span class="w"> </span>en_US.UTF-8
setenv<span class="w">          </span>RELION_QUEUE_USE<span class="w"> </span>yes
setenv<span class="w">          </span>RELION_QUEUE_NAME<span class="w"> </span>gpuQ
setenv<span class="w">          </span>RELION_QSUB_COMMAND<span class="w"> </span>qsub
setenv<span class="w">          </span>RELION_QSUB_EXTRA_COUNT<span class="w"> </span><span class="m">3</span>
setenv<span class="w">          </span>RELION_QSUB_EXTRA1<span class="w"> </span><span class="o">{</span>Number<span class="w"> </span>of<span class="w"> </span>Nodes<span class="o">}</span>
setenv<span class="w">          </span>RELION_QSUB_EXTRA2<span class="w"> </span><span class="o">{</span>Number<span class="w"> </span>of<span class="w"> </span>processes<span class="w"> </span>per<span class="w"> </span>each<span class="w"> </span>node<span class="o">}</span>
setenv<span class="w">          </span>RELION_QSUB_EXTRA3<span class="w"> </span><span class="o">{</span>Number<span class="w"> </span>of<span class="w"> </span>GPUs<span class="w"> </span>per<span class="w"> </span>node<span class="o">}</span>
setenv<span class="w">          </span>RELION_QSUB_EXTRA1_DEFAULT<span class="w"> </span><span class="m">1</span>
setenv<span class="w">          </span>RELION_QSUB_EXTRA2_DEFAULT<span class="w"> </span><span class="m">3</span>
setenv<span class="w">          </span>RELION_QSUB_EXTRA3_DEFAULT<span class="w"> </span><span class="m">2</span>
setenv<span class="w">          </span>RELION_CTFFIND_EXECUTABLE<span class="w"> </span>/tem/el7/ctffind-4.1.14/bin/ctffind
setenv<span class="w">          </span>RELION_GCTF_EXECUTABLE<span class="w"> </span>/tem/el7/Gctf_v1.18_b2/bin/Gctf_v1.18_b2_sm60_cu9.2
setenv<span class="w">          </span>RELION_RESMAP_EXECUTABLE<span class="w"> </span>/tem/el7/ResMap-1.1.4/ResMap-1.1.4-linux64
setenv<span class="w">          </span>RELION_MOTIONCOR2_EXECUTABLE<span class="w"> </span>/tem/el7/MotionCor2_v1.3.1/MotionCor2_v1.3.1-Cuda92
setenv<span class="w">          </span>RELION_UNBLUR_EXECUTABLE<span class="w"> </span>/tem/el7/unblur_1.0.2/bin/unblur_openmp_7_17_15.exe
setenv<span class="w">          </span>RELION_SUMMOVIE_EXECUTABLE<span class="w"> </span>/tem/el7/summovie_1.0.2/bin/sum_movie_openmp_7_17_15.exe
conflict<span class="w">        </span>apps/relion
-------------------------------------------------------------------

or

$&gt;<span class="w"> </span>module<span class="w"> </span>show<span class="w"> </span>apps/relion/cpu/4.0.0

-------------------------------------------------------------------
/tem/el7/Modules/apps/apps/relion/cpu/4.0.0:

module-whatis<span class="w">   </span><span class="o">{</span>Setups<span class="w"> </span>relion<span class="w"> </span><span class="m">4</span>.0.0<span class="w"> </span>environment<span class="w"> </span>variables<span class="o">}</span>
module<span class="w">          </span>load<span class="w"> </span>mpi/gcc/openmpi/4.0.3
setenv<span class="w">          </span>relion_version<span class="w"> </span><span class="m">4</span>.0.0
prepend-path<span class="w">    </span>PATH<span class="w"> </span>/tem/el7/relion-4.0.0/cpu/bin
prepend-path<span class="w">    </span>LD_LIBRARY_PATH<span class="w"> </span>/tem/el7/relion-4.0.0/cpu/lib
setenv<span class="w">          </span>LANG<span class="w"> </span>en_US.UTF-8
setenv<span class="w">          </span>RELION_QUEUE_USE<span class="w"> </span>yes
setenv<span class="w">          </span>RELION_QUEUE_NAME<span class="w"> </span>cpuQ
setenv<span class="w">          </span>RELION_QSUB_COMMAND<span class="w"> </span>qsub
setenv<span class="w">          </span>RELION_QSUB_EXTRA_COUNT<span class="w"> </span><span class="m">2</span>
setenv<span class="w">          </span>RELION_QSUB_EXTRA1<span class="w"> </span><span class="o">{</span>Number<span class="w"> </span>of<span class="w"> </span>Nodes<span class="o">}</span>
setenv<span class="w">          </span>RELION_QSUB_EXTRA2<span class="w"> </span><span class="o">{</span>Number<span class="w"> </span>of<span class="w"> </span>processes<span class="w"> </span>per<span class="w"> </span>each<span class="w"> </span>node<span class="o">}</span>
setenv<span class="w">          </span>RELION_QSUB_EXTRA1_DEFAULT<span class="w"> </span><span class="m">2</span>
setenv<span class="w">          </span>RELION_QSUB_EXTRA2_DEFAULT<span class="w"> </span><span class="m">16</span>
setenv<span class="w">          </span>RELION_CTFFIND_EXECUTABLE<span class="w"> </span>/tem/el7/ctffind-4.1.14/bin/ctffind
setenv<span class="w">          </span>RELION_GCTF_EXECUTABLE<span class="w"> </span>/tem/el7/Gctf_v1.18_b2/bin/Gctf_v1.18_b2_sm60_cu9.2
setenv<span class="w">          </span>RELION_RESMAP_EXECUTABLE<span class="w"> </span>/tem/el7/ResMap-1.1.4/ResMap-1.1.4-linux64
setenv<span class="w">          </span>RELION_MOTIONCOR2_EXECUTABLE<span class="w"> </span>/tem/el7/MotionCor2_v1.3.1/MotionCor2_v1.3.1-Cuda92
setenv<span class="w">          </span>RELION_UNBLUR_EXECUTABLE<span class="w"> </span>/tem/el7/unblur_1.0.2/bin/unblur_openmp_7_17_15.exe
setenv<span class="w">          </span>RELION_SUMMOVIE_EXECUTABLE<span class="w"> </span>/tem/el7/summovie_1.0.2/bin/sum_movie_openmp_7_17_15.exe
conflict<span class="w">        </span>apps/relion
-------------------------------------------------------------------
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p>Load the environment module for the version of relion application which you want to execute. As the module specified is loaded, all the modules with dependency are also loaded (you can check these modules with “module list” command)</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$&gt;<span class="w"> </span>module<span class="w"> </span>load<span class="w"> </span>apps/relion/gpu/4.0.0
$&gt;<span class="w"> </span>module<span class="w"> </span>list
Currently<span class="w"> </span>Loaded<span class="w"> </span>Modulefiles:
<span class="w">  </span><span class="m">1</span><span class="o">)</span><span class="w"> </span>mpi/gcc/openmpi/4.0.3<span class="w">   </span><span class="m">2</span><span class="o">)</span><span class="w"> </span>cuda/11.2<span class="w">   </span><span class="m">3</span><span class="o">)</span><span class="w"> </span>apps/relion/gpu/4.0.0
</pre></div>
</div>
<ol class="arabic simple" start="4">
<li><p>Check the relion application binary path</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$&gt;<span class="w"> </span>which<span class="w"> </span>relion
/tem/el7/relion-4.0.0/gpu/bin/relion
</pre></div>
</div>
<ol class="arabic simple" start="5">
<li><p>Execute the relion application (we assume that X11 forwarding is enabled)</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$&gt;<span class="w"> </span>relion
</pre></div>
</div>
<a class="reference internal image-reference" href="_images/relion-screenshot.png"><img alt="_images/relion-screenshot.png" class="align-center" src="_images/relion-screenshot.png" style="width: 798.0px; height: 797.0px;" /></a>
</section>
</section>
<section id="pbs-strings-used-in-relion">
<h2>PBS Strings used in Relion<a class="headerlink" href="#pbs-strings-used-in-relion" title="Permalink to this heading"></a></h2>
<table class="docutils align-default" id="id2">
<caption><span class="caption-text">torque_strings_of_relion</span><a class="headerlink" href="#id2" title="Permalink to this table"></a></caption>
<tbody>
<tr class="row-odd"><td><p>String</p></td>
<td><p>Variable type</p></td>
<td><p>Description</p></td>
</tr>
<tr class="row-even"><td><p><strong>XXXcommandXXX</strong></p></td>
<td><p>string</p></td>
<td><p>relion command + arguments</p></td>
</tr>
<tr class="row-odd"><td><p><strong>XXXqueueXXX</strong></p></td>
<td><p>string</p></td>
<td><p>Name of the queue to submit job to</p></td>
</tr>
<tr class="row-even"><td><p><strong>XXXmpinodesXXX</strong></p></td>
<td><p>integer</p></td>
<td><p>The number of MPI processes to use</p></td>
</tr>
<tr class="row-odd"><td><p><strong>XXXthreadsXXX</strong></p></td>
<td><p>integer</p></td>
<td><p>The number of threads to use on each MPI process</p></td>
</tr>
<tr class="row-even"><td><p><strong>XXXcoresXXX</strong></p></td>
<td><p>integer</p></td>
<td><p>The number of MPI processes times the number of threads</p></td>
</tr>
<tr class="row-odd"><td><p><strong>XXXdedicatedXXX</strong></p></td>
<td><p>integer</p></td>
<td><p>The minimum number of cores on each node
(use this to fill entire nodes)</p></td>
</tr>
<tr class="row-even"><td><p><strong>XXXnodesXXX</strong></p></td>
<td><p>integer</p></td>
<td><p>The total number of nodes to be requested</p></td>
</tr>
<tr class="row-odd"><td><p><strong>XXXextra1XXX</strong></p></td>
<td><p>string</p></td>
<td><p>Installation-specific</p></td>
</tr>
<tr class="row-even"><td><p><strong>XXXextra2XXX</strong></p></td>
<td><p>string</p></td>
<td><p>Installation-specific</p></td>
</tr>
</tbody>
</table>
<p>Relion, by default, does not use the XXXextra1XXX, XXXextra2XXX, … variables.
They provide additional flexibility for queueing systems (like Torque) that require additional variables.
They may be activated by first setting RELION_QSUB_EXTRA_COUNT to the number of fields you need (e.g. 3) and then setting the RELION_QSUB_EXTRA1, RELION_QSUB_EXTRA2, RELION_QSUB_EXTRA3 … environment variables, respectively.
This will result in extra input fields in the GUI, with the label text being equal to the value of the environment variable. Likewise, their default values (upon starting the GUI) can be set through environment variables RELION_QSUB_EXTRA1_DEFAULT, RELION_QSUB_EXTRA2_DEFAULT, etc and their help messages can be set through environmental variables RELION_QSUB_EXTRA1_HELP, RELION_QSUB_EXTRA2_HELP and so on.</p>
</section>
<section id="running-data-analysis-jobs-using-cpu-cores">
<h2>Running data analysis jobs using CPU cores<a class="headerlink" href="#running-data-analysis-jobs-using-cpu-cores" title="Permalink to this heading"></a></h2>
<section id="module-path">
<h3>Module path<a class="headerlink" href="#module-path" title="Permalink to this heading"></a></h3>
<p>Users should load an environment module, whose path is  <strong>apps/relion/cpu/X.X.X</strong> (i.e., moulde load apps/relion/cpu/4.0.0) to execute data analysis jobs using CPU cores in relion GUI.</p>
<ul class="simple">
<li><p>apps/relion/cpu/3.0.7</p></li>
<li><p>apps/relion/cpu/3.1.0</p></li>
<li><p>apps/relion/cpu/4.0.0</p></li>
</ul>
</section>
<section id="environment-variables">
<h3>Environment variables<a class="headerlink" href="#environment-variables" title="Permalink to this heading"></a></h3>
<p>Relion defines a lot of environment variables that can be used to execute different types of subtasks in the analysis workflows. Among these, “RELION_QSUB_TEMPLATE” describes the location of a proper batch job script template (usually called standard job submission script) to submit jobs to the farm.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">(</span><span class="k">for</span><span class="w"> </span>relion<span class="w"> </span><span class="m">3</span>.0.7<span class="w"> </span>standard<span class="w"> </span>job<span class="w"> </span>submission<span class="w"> </span>script<span class="o">)</span><span class="w"> </span>RELION_QSUB_TEMPLATE<span class="w"> </span>/tem/el7/qsub-relion-3.0.7-cpu.bash
<span class="o">(</span><span class="k">for</span><span class="w"> </span>relion<span class="w"> </span><span class="m">3</span>.1.0<span class="w"> </span>standard<span class="w"> </span>job<span class="w"> </span>submission<span class="w"> </span>script<span class="o">)</span><span class="w"> </span>RELION_QSUB_TEMPLATE<span class="w"> </span>/tem/el7/qsub-relion-3.1.0-cpu.bash
<span class="o">(</span><span class="k">for</span><span class="w"> </span>relion<span class="w"> </span><span class="m">4</span>.0.0<span class="w"> </span>standard<span class="w"> </span>job<span class="w"> </span>submission<span class="w"> </span>script<span class="o">)</span><span class="w"> </span>RELION_QSUB_TEMPLATE<span class="w"> </span>/tem/el7/qsub-relion-4.0.0-cpu.bash
</pre></div>
</div>
<p>For the use of CPU cluster nodes, we have set the RELION_QSUB_EXTRA_COUNT to 2. Two extra options describe “Number of Nodes” and “Number of processes per each node”, respectively. These values can be referred by XXXextra1, XXXextra2XXX in the following batch job script template.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>setenv<span class="w"> </span>RELION_QSUB_EXTRA_COUNT<span class="w"> </span><span class="m">2</span>
setenv<span class="w"> </span>RELION_QSUB_EXTRA1<span class="w"> </span><span class="s2">&quot;Number of Nodes&quot;</span>
setenv<span class="w"> </span>RELION_QSUB_EXTRA2<span class="w"> </span><span class="s2">&quot;Number of processes per each node&quot;</span>
setenv<span class="w"> </span>RELION_QSUB_EXTRA1_DEFAULT<span class="w"> </span><span class="m">2</span>
setenv<span class="w"> </span>RELION_QSUB_EXTRA2_DEFAULT<span class="w"> </span><span class="m">16</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="_images/relion-cpu.jpg"><img alt="_images/relion-cpu.jpg" class="align-center" src="_images/relion-cpu.jpg" style="width: 803.5999999999999px; height: 787.5px;" /></a>
<p>As shown in above figure, you can browse and select <strong>“standard submission script”</strong> as the location of RELION_QSUB_TEMPLATE for relion X.X.X (i.e., /tem/el7/qsub-relion-4.0.0-cpu.bash or its own your copy),
and give <strong>“Number of Nodes”</strong> and <strong>“Number of processes per each node”</strong> values instead of default ones to submit a job to Torque based TEM farm.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For CPU jobs, note that you <strong>MUST</strong> use <strong>cpuQ</strong> for the “Queue name” field and render correct “number of MPI procs” which is generally total number of processes (# of nodes * # of processes per each node)</p>
</div>
</section>
<section id="standard-job-submission-script-for-relion-4-0-0-cpu-use">
<h3>Standard job submission script (for relion 4.0.0 CPU use)<a class="headerlink" href="#standard-job-submission-script-for-relion-4-0-0-cpu-use" title="Permalink to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>

<span class="c1">### Inherit all current environment variables</span>
<span class="c1">#PBS -V</span>

<span class="c1">### Job name</span>
<span class="c1">#PBS -N XXXnameXXX</span>

<span class="c1">### Queue name</span>
<span class="c1">#PBS -q XXXqueueXXX</span>

<span class="c1">### CPU cluster use : Specify the number of nodes (XXXextra1XXX) and the number of processes per each node (XXXextra2XXX)</span>
<span class="c1">#PBS -l nodes=XXXextra1XXX:ppn=XXXextra2XXX:XXXqueueXXX</span>

<span class="c1">#PBS -o ${PBS_JOBNAME}/run.out</span>
<span class="c1">#PBS -e ${PBS_JOBNAME}/run.err</span>

<span class="c1">###########################################################</span>
<span class="c1">### Print Environment Variables</span>
<span class="c1">###########################################################</span>
<span class="nb">echo</span><span class="w"> </span>------------------------------------------------------
<span class="nb">echo</span><span class="w"> </span>-n<span class="w"> </span><span class="s1">&#39;Job is running on node &#39;</span><span class="p">;</span><span class="w"> </span>cat<span class="w"> </span><span class="nv">$PBS_NODEFILE</span>
<span class="nb">echo</span><span class="w"> </span>------------------------------------------------------
<span class="nb">echo</span><span class="w"> </span>PBS:<span class="w"> </span>qsub<span class="w"> </span>is<span class="w"> </span>running<span class="w"> </span>on<span class="w"> </span><span class="nv">$PBS_O_HOST</span>
<span class="nb">echo</span><span class="w"> </span>PBS:<span class="w"> </span>originating<span class="w"> </span>queue<span class="w"> </span>is<span class="w"> </span><span class="nv">$PBS_O_QUEUE</span>
<span class="nb">echo</span><span class="w"> </span>PBS:<span class="w"> </span>executing<span class="w"> </span>queue<span class="w"> </span>is<span class="w"> </span><span class="nv">$PBS_QUEUE</span>
<span class="nb">echo</span><span class="w"> </span>PBS:<span class="w"> </span>working<span class="w"> </span>directory<span class="w"> </span>is<span class="w"> </span><span class="nv">$PBS_O_WORKDIR</span>
<span class="nb">echo</span><span class="w"> </span>PBS:<span class="w"> </span>execution<span class="w"> </span>mode<span class="w"> </span>is<span class="w"> </span><span class="nv">$PBS_ENVIRONMENT</span>
<span class="nb">echo</span><span class="w"> </span>PBS:<span class="w"> </span>job<span class="w"> </span>identifier<span class="w"> </span>is<span class="w"> </span><span class="nv">$PBS_JOBID</span>
<span class="nb">echo</span><span class="w"> </span>PBS:<span class="w"> </span>job<span class="w"> </span>name<span class="w"> </span>is<span class="w"> </span><span class="nv">$PBS_JOBNAME</span>
<span class="nb">echo</span><span class="w"> </span>PBS:<span class="w"> </span>node<span class="w"> </span>file<span class="w"> </span>is<span class="w"> </span><span class="nv">$PBS_NODEFILE</span>
<span class="nb">echo</span><span class="w"> </span>PBS:<span class="w"> </span>current<span class="w"> </span>home<span class="w"> </span>directory<span class="w"> </span>is<span class="w"> </span><span class="nv">$PBS_O_HOME</span>
<span class="nb">echo</span><span class="w"> </span>PBS:<span class="w"> </span><span class="nv">PATH</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">$PBS_O_PATH</span>
<span class="nb">echo</span><span class="w"> </span>------------------------------------------------------

<span class="c1">###########################################################</span>
<span class="c1"># Switch to the working directory;</span>
<span class="nb">cd</span><span class="w"> </span><span class="si">${</span><span class="nv">PBS_O_WORKDIR</span><span class="si">}</span>/<span class="si">${</span><span class="nv">PBS_JOBNAME</span><span class="si">}</span>
touch<span class="w"> </span>run.out
touch<span class="w"> </span>run.err
<span class="nb">cd</span><span class="w"> </span><span class="nv">$PBS_O_WORKDIR</span>
<span class="c1">###########################################################</span>

<span class="c1">### Run:</span>
module<span class="w"> </span>load<span class="w"> </span>apps/relion/cpu/4.0.0
mpirun<span class="w"> </span>--mca<span class="w"> </span>btl<span class="w"> </span>tcp,self<span class="w"> </span>--mca<span class="w"> </span>btl_tcp_if_exclude<span class="w"> </span>lo,docker0<span class="w"> </span>--prefix<span class="w"> </span>/tem/el7/openmpi-4.0.3<span class="w"> </span>-machinefile<span class="w"> </span><span class="nv">$PBS_NODEFILE</span><span class="w"> </span>XXXcommandXXX

<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Done!&quot;</span>
</pre></div>
</div>
</section>
</section>
<section id="running-data-analysis-jobs-using-gpgpus">
<h2>Running data analysis jobs using GPGPUs<a class="headerlink" href="#running-data-analysis-jobs-using-gpgpus" title="Permalink to this heading"></a></h2>
<section id="id1">
<h3>Environment variables<a class="headerlink" href="#id1" title="Permalink to this heading"></a></h3>
<p>Relion defines a lot of environment variables that can be used to execute different types of subtasks in the analysis workflows. Among these, “RELION_QSUB_TEMPLATE” describes the location of a proper batch job script to submit jobs to the farm.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">(</span><span class="k">for</span><span class="w"> </span>relion<span class="w"> </span><span class="m">3</span>.0.7<span class="w"> </span>w/<span class="w"> </span>GPU<span class="w"> </span>support<span class="w"> </span>standard<span class="w"> </span>job<span class="w"> </span>submission<span class="w"> </span>script<span class="o">)</span><span class="w"> </span>RELION_QSUB_TEMPLATE<span class="w"> </span>/tem/el7/qsub-relion-3.0.7-gpu.bash
<span class="o">(</span><span class="k">for</span><span class="w"> </span>relion<span class="w"> </span><span class="m">3</span>.1.0<span class="w"> </span>w/<span class="w"> </span>GPU<span class="w"> </span>support<span class="w"> </span>standard<span class="w"> </span>job<span class="w"> </span>submission<span class="w"> </span>script<span class="o">)</span><span class="w"> </span>RELION_QSUB_TEMPLATE<span class="w"> </span>/tem/el7/qsub-relion-3.1.0-gpu.bash
<span class="o">(</span><span class="k">for</span><span class="w"> </span>relion<span class="w"> </span><span class="m">4</span>.0.0<span class="w"> </span>w/<span class="w"> </span>GPU<span class="w"> </span>support<span class="w"> </span>standard<span class="w"> </span>job<span class="w"> </span>submission<span class="w"> </span>script<span class="o">)</span><span class="w"> </span>RELION_QSUB_TEMPLATE<span class="w"> </span>/tem/el7/qsub-relion-4.0.0-gpu.bash
</pre></div>
</div>
<p>Unlike CPU cluster use case, we have set the RELION_QSUB_EXTRA_COUNT to 3 for the use of GPGPU cluster,
where each extra option describes “Number of Nodes”, “Number of processes per each node”, and “Number of GPUs per node”, respectively. All these values can be accessed by XXXextra1, XXXextra2XXX, XXXextra3XXX
in the batch job script template.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>setenv<span class="w"> </span>RELION_QSUB_EXTRA_COUNT<span class="w"> </span><span class="m">3</span>
setenv<span class="w"> </span>RELION_QSUB_EXTRA1<span class="w"> </span><span class="s2">&quot;Number of Nodes&quot;</span>
setenv<span class="w"> </span>RELION_QSUB_EXTRA2<span class="w"> </span><span class="s2">&quot;Number of processes per each node&quot;</span>
setenv<span class="w"> </span>RELION_QSUB_EXTRA3<span class="w"> </span><span class="s2">&quot;Number of GPUs per node&quot;</span>
setenv<span class="w"> </span>RELION_QSUB_EXTRA1_DEFAULT<span class="w"> </span><span class="m">1</span>
setenv<span class="w"> </span>RELION_QSUB_EXTRA2_DEFAULT<span class="w"> </span><span class="m">3</span>
setenv<span class="w"> </span>RELION_QSUB_EXTRA3_DEFAULT<span class="w"> </span><span class="m">2</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="_images/relion-script-description.png"><img alt="_images/relion-script-description.png" class="align-center" src="_images/relion-script-description.png" style="width: 785.4px; height: 787.5px;" /></a>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For GPU jobs, note that you <strong>MUST</strong> use <strong>gpuQ</strong> for the “Queue name” field and render correct “number of MPI procs” which is generally total number of processes (# of nodes * # of processes per each node)</p>
</div>
</section>
<section id="standard-job-submission-script-for-relion-4-0-0-gpgpu-use">
<h3>Standard job submission script (for relion 4.0.0 GPGPU use)<a class="headerlink" href="#standard-job-submission-script-for-relion-4-0-0-gpgpu-use" title="Permalink to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>

<span class="c1">### Inherit all current environment variables</span>
<span class="c1">#PBS -V</span>

<span class="c1">### Job name</span>
<span class="c1">#PBS -N XXXnameXXX</span>

<span class="c1">### Queue name</span>
<span class="c1">#PBS -q XXXqueueXXX</span>

<span class="c1">### GPU use : Specify the number of nodes (XXXextra1XXX), the number of processes per each node (XXXextra2XXX), and the number of GPGPUs per node (XXXextra3XXX)</span>
<span class="c1">#PBS -l nodes=XXXextra1XXX:ppn=XXXextra2XXX:gpus=XXXextra3XXX:XXXqueueXXX</span>

<span class="c1">#PBS -o ${PBS_JOBNAME}/run.out</span>
<span class="c1">#PBS -e ${PBS_JOBNAME}/run.err</span>

<span class="c1">###########################################################</span>
<span class="c1">### Print Environment Variables</span>
<span class="c1">###########################################################</span>
<span class="nb">echo</span><span class="w"> </span>------------------------------------------------------
<span class="nb">echo</span><span class="w"> </span>-n<span class="w"> </span><span class="s1">&#39;Job is running on node &#39;</span><span class="p">;</span><span class="w"> </span>cat<span class="w"> </span><span class="nv">$PBS_NODEFILE</span>
<span class="nb">echo</span><span class="w"> </span>------------------------------------------------------
<span class="nb">echo</span><span class="w"> </span>PBS:<span class="w"> </span>qsub<span class="w"> </span>is<span class="w"> </span>running<span class="w"> </span>on<span class="w"> </span><span class="nv">$PBS_O_HOST</span>
<span class="nb">echo</span><span class="w"> </span>PBS:<span class="w"> </span>originating<span class="w"> </span>queue<span class="w"> </span>is<span class="w"> </span><span class="nv">$PBS_O_QUEUE</span>
<span class="nb">echo</span><span class="w"> </span>PBS:<span class="w"> </span>executing<span class="w"> </span>queue<span class="w"> </span>is<span class="w"> </span><span class="nv">$PBS_QUEUE</span>
<span class="nb">echo</span><span class="w"> </span>PBS:<span class="w"> </span>working<span class="w"> </span>directory<span class="w"> </span>is<span class="w"> </span><span class="nv">$PBS_O_WORKDIR</span>
<span class="nb">echo</span><span class="w"> </span>PBS:<span class="w"> </span>execution<span class="w"> </span>mode<span class="w"> </span>is<span class="w"> </span><span class="nv">$PBS_ENVIRONMENT</span>
<span class="nb">echo</span><span class="w"> </span>PBS:<span class="w"> </span>job<span class="w"> </span>identifier<span class="w"> </span>is<span class="w"> </span><span class="nv">$PBS_JOBID</span>
<span class="nb">echo</span><span class="w"> </span>PBS:<span class="w"> </span>job<span class="w"> </span>name<span class="w"> </span>is<span class="w"> </span><span class="nv">$PBS_JOBNAME</span>
<span class="nb">echo</span><span class="w"> </span>PBS:<span class="w"> </span>node<span class="w"> </span>file<span class="w"> </span>is<span class="w"> </span><span class="nv">$PBS_NODEFILE</span>
<span class="nb">echo</span><span class="w"> </span>PBS:<span class="w"> </span>current<span class="w"> </span>home<span class="w"> </span>directory<span class="w"> </span>is<span class="w"> </span><span class="nv">$PBS_O_HOME</span>
<span class="nb">echo</span><span class="w"> </span>PBS:<span class="w"> </span><span class="nv">PATH</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">$PBS_O_PATH</span>
<span class="nb">echo</span><span class="w"> </span>PBS:<span class="w"> </span><span class="nv">PBS_GPUFILE</span><span class="o">=</span><span class="nv">$PBS_GPUFILE</span>
<span class="nb">echo</span><span class="w"> </span>PBS:<span class="w"> </span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="nv">$CUDA_VISIBLE_DEVICES</span>
<span class="nb">echo</span><span class="w"> </span>------------------------------------------------------

<span class="c1">###########################################################</span>
<span class="c1"># Switch to the working directory;</span>
<span class="nb">cd</span><span class="w"> </span><span class="si">${</span><span class="nv">PBS_O_WORKDIR</span><span class="si">}</span>/<span class="si">${</span><span class="nv">PBS_JOBNAME</span><span class="si">}</span>
touch<span class="w"> </span>run.out
touch<span class="w"> </span>run.err
<span class="nb">cd</span><span class="w"> </span><span class="nv">$PBS_O_WORKDIR</span>
<span class="c1">###########################################################</span>

<span class="c1">### Run:</span>
module<span class="w"> </span>load<span class="w"> </span>apps/relion/gpu/4.0.0
mpirun<span class="w"> </span>--mca<span class="w"> </span>btl<span class="w"> </span>tcp,self<span class="w"> </span>--mca<span class="w"> </span>btl_tcp_if_exclude<span class="w"> </span>lo,docker0<span class="w"> </span>--prefix<span class="w"> </span>/tem/el7/openmpi-4.0.3<span class="w"> </span>-machinefile<span class="w"> </span><span class="nv">$PBS_NODEFILE</span><span class="w"> </span>XXXcommandXXX

<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Done!&quot;</span>
</pre></div>
</div>
</section>
<section id="specifying-which-gpgpus-to-use">
<h3>Specifying which GPGPUs to use<a class="headerlink" href="#specifying-which-gpgpus-to-use" title="Permalink to this heading"></a></h3>
<a class="reference internal image-reference" href="_images/relion-gpu-node-allocation.png"><img alt="_images/relion-gpu-node-allocation.png" class="align-center" src="_images/relion-gpu-node-allocation.png" style="width: 964.5999999999999px; height: 687.4px;" /></a>
<p>Here, we describe more advanced syntax for restricting RELION processes to certain GPUs on multi-GPU setups. You can use an argument to the –gpu option to provide a list of device-indices. The syntax is then to delimit ranks with colons [:], and threads by commas [,]. Any GPU indices provided is taken to be a list which is repeated if shorter than the total number of GPUs. By extension, the following rules applies</p>
<p>If a GPU id is specified more than once for a single mpi-rank, that GPU will be assigned proprotionally more of the threads of that rank.
If no colons are used (i.e. GPUs are only specified for a single rank), then the GPUs specified, apply to all ranks.
If GPUs are specified for more than one rank but not for all ranks, the unrestricted ranks are assigned the same GPUs as the restricted ranks, by a modulo rule.
For example, if you would only want to use two of the four GPUs for all mpi-ranks, because you want to leave another two free for a different user/job, then (by the above rule 2) you can specify</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mpirun<span class="w"> </span>-n<span class="w"> </span><span class="m">3</span><span class="w"> </span>‘which<span class="w"> </span>relion_refine_mpi‘<span class="w"> </span>--gpu<span class="w"> </span><span class="m">2</span>:3
slave<span class="w"> </span><span class="m">1</span><span class="w"> </span>is<span class="w"> </span>told<span class="w"> </span>to<span class="w"> </span>use<span class="w"> </span>GPU2.<span class="w"> </span>slave<span class="w"> </span><span class="m">2</span><span class="w"> </span>is<span class="w"> </span>told<span class="w"> </span>to<span class="w"> </span>use<span class="w"> </span>GPU3.
</pre></div>
</div>
<p>If you want an even spread over ALL GPUs, then you should not specify selection indices, as RELION will handle this itself. On your hypothetical 4-GPU machine, you would simply say</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mpirun<span class="w"> </span>-n<span class="w"> </span><span class="m">3</span><span class="w"> </span>‘which<span class="w"> </span>relion_refine_mpi‘<span class="w"> </span>--gpu
<span class="c1">## slave 1 will use GPU0 and GPU1 for its threads. slave 2 will use GPU2 and GPU3 for its threads</span>
</pre></div>
</div>
<p>One can also schedule individual threads from MPI processes on the GPUs. This would be most useful when available RAM would be a limitation. Then one could for example run 3 MPI processes, each of which spawn a number of threads on two of the cards each, as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mpirun<span class="w"> </span>-n<span class="w"> </span><span class="m">3</span><span class="w"> </span>‘which<span class="w"> </span>relion_refine_mpi‘<span class="w"> </span>--j<span class="w"> </span><span class="m">4</span><span class="w"> </span>--gpu<span class="w"> </span><span class="m">0</span>,1,1,2:3
<span class="c1">## slave 1 is told to put thread 1 on GPU0, threads 2 and 3 on GPU1, and thread 4 on GPU2.  slave 2 is told to put all 4 threads on GPU3.</span>
</pre></div>
</div>
<p>Finally, for completeness, the following is a more complex example to illustrate the full functionality of the GPU-device specification options.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mpirun<span class="w"> </span>-n<span class="w"> </span><span class="m">4</span><span class="w"> </span>...<span class="w"> </span>-j<span class="w"> </span><span class="m">3</span><span class="w"> </span>--gpu<span class="w"> </span><span class="m">2</span>:2:1,3
<span class="c1">## slave 1 w/ 3 threads on GPU2, slave 2 w/ 3 threads on GPU2, slave 3 distributes 3 threads as evenly as possible across GPU1 and GPU3.</span>
</pre></div>
</div>
<p>For more information, please refer to Relion Benchmarks and computer hardware (<a class="reference external" href="https://www3.mrc-lmb.cam.ac.uk/relion/index.php/Benchmarks_%26_computer_hardware">https://www3.mrc-lmb.cam.ac.uk/relion/index.php/Benchmarks_%26_computer_hardware</a>)</p>
</section>
</section>
<section id="examples">
<h2>Examples<a class="headerlink" href="#examples" title="Permalink to this heading"></a></h2>
<section id="motion-correction">
<h3>Motion Correction<a class="headerlink" href="#motion-correction" title="Permalink to this heading"></a></h3>
<ul class="simple">
<li><p><strong>MotionCor2-like alignment algorithm</strong> (CPU-only job, relion-own implementation)</p>
<ul>
<li><p>(Motion) Use RELION’s own implementation? : Yes</p></li>
<li><p>(Running) Number of MPI Procs : 84</p></li>
<li><p>(Running) Number of threads : 1</p></li>
<li><p>(Running) Queue name : <strong>cpuQ</strong></p></li>
<li><p>(Running) Resource Requirements : nodes=3:ppn=28  (e.g., we assume that the job is allocated to the 3 nodes which have all 28 cores available for each node)</p></li>
<li><p>(Running) Standard submission script :</p>
<ul>
<li><p>/tem/el7/qsub-relion-3.0.7-cpu.bash           ## Relion 3.0.7 CPU MPI 작업 템플릿</p></li>
<li><p>/tem/el7/qsub-relion-3.1.0-cpu.bash           ## Relion 3.1.0 CPU MPI 작업 템플릿</p></li>
<li><p>/tem/el7/qsub-relion-4.0.0-cpu.bash           ## Relion 4.0.0 CPU MPI 작업 템플릿</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<a class="reference internal image-reference" href="_images/relion-motioncor1.png"><img alt="_images/relion-motioncor1.png" class="align-center" src="_images/relion-motioncor1.png" style="width: 796.0px; height: 756.0px;" /></a>
<a class="reference internal image-reference" href="_images/relion-motioncor2.png"><img alt="_images/relion-motioncor2.png" class="align-center" src="_images/relion-motioncor2.png" style="width: 798.0px; height: 759.0px;" /></a>
<ul class="simple">
<li><p><strong>MotionCor2</strong> (GPU-accelerated job)</p>
<ul>
<li><p>(Motion) Use RELION’s own implementation? : No</p></li>
<li><p>(Motion) MOTIONCOR2 executable : /tem/home/tem/_Applications/MotionCor2/MotionCor2_Cuda9.1_v1.0.5</p></li>
<li><p>(Running) Number of MPI Procs : 2</p></li>
<li><p>(Running) Number of threads : 1</p></li>
<li><p>(Running) Queue name : <strong>gpuQ</strong></p></li>
<li><p>(Running) Resource Requirements : nodes=1:ppn=3:gpus=2  (e.g., we assume that the job is allocated to 1 node which has 3 cpu cores and 2 GPU devices available)</p></li>
<li><p>(Running) Standard submission script :</p>
<ul>
<li><p>/tem/el7/qsub-relion-3.0.7-gpu.bash           ## Relion 3.0.7 GPU 가속 활용하는 MPI 작업 템플릿</p></li>
<li><p>/tem/el7/qsub-relion-3.1.0-gpu.bash           ## Relion 3.1.0 GPU 가속 활용하는 MPI 작업 템플릿</p></li>
<li><p>/tem/el7/qsub-relion-4.0.0-gpu.bash           ## Relion 4.0.0 GPU 가속 활용하는 MPI 작업 템플릿</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<a class="reference internal image-reference" href="_images/motioncor2-1.png"><img alt="_images/motioncor2-1.png" class="align-center" src="_images/motioncor2-1.png" style="width: 793.0px; height: 758.0px;" /></a>
<a class="reference internal image-reference" href="_images/motioncor2-2.png"><img alt="_images/motioncor2-2.png" class="align-center" src="_images/motioncor2-2.png" style="width: 793.0px; height: 761.0px;" /></a>
</section>
<section id="ctf-estimation">
<h3>CTF Estimation<a class="headerlink" href="#ctf-estimation" title="Permalink to this heading"></a></h3>
<ul class="simple">
<li><p><strong>CTFFIND-4.1</strong> (CPU-only job)</p>
<ul>
<li><p>(CTFFIND-4.1) Use CTFFIND-4.1? : Yes</p></li>
<li><p>(CTFFIND-4.1) CTFFIND-4.1 executable? : /tem/el7/ctffind-4.1.14/bin/ctffind</p></li>
<li><p>(Gctf) Use Gctf instead? : No</p></li>
<li><p>(Running) Number of MPI procs: 48</p></li>
<li><p>(Running) Submit to queue? : Yes</p></li>
<li><p>(Running) Queue name : <strong>cpuQ</strong></p></li>
<li><p>(Running) Resource Requirements : nodes=3:ppn=16  (e.g., we assume the use of 3 nodes, 16 cpu cores per each node)</p></li>
<li><p>(Running) Standard submission script :</p>
<ul>
<li><p>/tem/el7/qsub-relion-3.0.7-cpu.bash           ## Relion 3.0.7 CPU MPI 작업 템플릿</p></li>
<li><p>/tem/el7/qsub-relion-3.1.0-cpu.bash           ## Relion 3.1.0 CPU MPI 작업 템플릿</p></li>
<li><p>/tem/el7/qsub-relion-4.0.0-cpu.bash           ## Relion 4.0.0 CPU MPI 작업 템플릿</p></li>
<li><p>/tem/el7/qsub-relion-4.0.0-cpu.bash           ## Relion 4.0.0 CPU MPI 작업 템플릿</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<a class="reference internal image-reference" href="_images/ctffind-1.png"><img alt="_images/ctffind-1.png" class="align-center" src="_images/ctffind-1.png" style="width: 795.0px; height: 758.0px;" /></a>
<a class="reference internal image-reference" href="_images/ctffind-2.png"><img alt="_images/ctffind-2.png" class="align-center" src="_images/ctffind-2.png" style="width: 794.0px; height: 759.0px;" /></a>
<ul class="simple">
<li><p><strong>Gctf</strong> (GPU-accelerated job)</p>
<ul>
<li><p>(CTFFIND-4.1) Use CTFFIND-4.1? : No</p></li>
<li><p>(Gctf) Use Gctf instead? : Yes</p></li>
<li><p>(Gctf) Gctf executable: /tem/el7/Gctf_v1.18_b2/bin/Gctf_v1.18_b2_sm60_cu9.2</p></li>
<li><p>(Gctf) Which GPUs to use: &lt;empty&gt; (i.e., relion automatically assigned available GPU devices to the MPI processes)</p></li>
<li><p>(Running) Number of MPI procs: 5 (1 master and 4 slave processes)</p></li>
<li><p>(Running) Submit to queue? : Yes</p></li>
<li><p>(Running) Queue name : <strong>gpuQ</strong></p></li>
<li><p>(Running) Resource Requirements : nodes=1:ppn=5:gpus=2</p></li>
<li><p>(Running) Standard submission script :</p>
<ul>
<li><p>/tem/el7/qsub-relion-3.0.7-gpu.bash           ## Relion 3.0.7 GPU 가속 활용하는 MPI 작업 템플릿</p></li>
<li><p>/tem/el7/qsub-relion-3.1.0-gpu.bash           ## Relion 3.1.0 GPU 가속 활용하는 MPI 작업 템플릿</p></li>
<li><p>/tem/el7/qsub-relion-4.0.0-gpu.bash           ## Relion 4.0.0 GPU 가속 활용하는 MPI 작업 템플릿</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<a class="reference internal image-reference" href="_images/gctf-1.png"><img alt="_images/gctf-1.png" class="align-center" src="_images/gctf-1.png" style="width: 795.0px; height: 758.0px;" /></a>
<a class="reference internal image-reference" href="_images/gctf-2.png"><img alt="_images/gctf-2.png" class="align-center" src="_images/gctf-2.png" style="width: 795.0px; height: 758.0px;" /></a>
</section>
<section id="d-classification">
<h3>2D Classification<a class="headerlink" href="#d-classification" title="Permalink to this heading"></a></h3>
<ul class="simple">
<li><p><strong>relion_refine_mpi</strong> (CPU-only job)</p>
<ul>
<li><p>(Compute) Use GPU acceleration? : No</p></li>
<li><p>(Running) Number of MPI procs: 112</p></li>
<li><p>(Running) Number of threads: 1</p></li>
<li><p>(Running) Submit to queue? : Yes</p></li>
<li><p>(Running) Queue name : <strong>cpuQ</strong></p></li>
<li><p>(Running) Resource Requirements : nodes=4:ppn=28  (e.g., we assume the use of 4 nodes, 28 cpu cores per each node)</p></li>
<li><p>(Running) Standard submission script :</p>
<ul>
<li><p>/tem/el7/qsub-relion-3.0.7-cpu.bash           ## Relion 3.0.7 CPU MPI 작업 템플릿</p></li>
<li><p>/tem/el7/qsub-relion-3.1.0-cpu.bash           ## Relion 3.1.0 CPU MPI 작업 템플릿</p></li>
<li><p>/tem/el7/qsub-relion-4.0.0-cpu.bash           ## Relion 4.0.0 CPU MPI 작업 템플릿</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<a class="reference internal image-reference" href="_images/2dclass-1.png"><img alt="_images/2dclass-1.png" class="align-center" src="_images/2dclass-1.png" style="width: 795.0px; height: 757.0px;" /></a>
<a class="reference internal image-reference" href="_images/2dclass-2.png"><img alt="_images/2dclass-2.png" class="align-center" src="_images/2dclass-2.png" style="width: 794.0px; height: 757.0px;" /></a>
<ul class="simple">
<li><p><strong>relion_refine_mpi</strong> (GPU-accelerated job)</p>
<ul>
<li><p>(Compute) Use GPU acceleration? : Yes</p></li>
<li><p>(Compute) Which GPUs to use? : 0:1 (i.e., we will assign each slave process to GPU device index 0 and 1, respectively)</p></li>
<li><p>(Running) Number of MPI procs: 3 (1 master and 2 slave processes)</p></li>
<li><p>(Running) Number of threads: 1</p></li>
<li><p>(Running) Submit to queue? : Yes</p></li>
<li><p>(Running) Queue name : <strong>gpuQ</strong></p></li>
<li><p>(Running) Resource Requirements : nodes=1:ppn=3:gpus=2</p></li>
<li><p>(Running) Standard submission script :</p>
<ul>
<li><p>/tem/el7/qsub-relion-3.0.7-gpu.bash           ## Relion 3.0.7 GPU 가속 활용하는 MPI 작업 템플릿</p></li>
<li><p>/tem/el7/qsub-relion-3.1.0-gpu.bash           ## Relion 3.1.0 GPU 가속 활용하는 MPI 작업 템플릿</p></li>
<li><p>/tem/el7/qsub-relion-4.0.0-gpu.bash           ## Relion 4.0.0 GPU 가속 활용하는 MPI 작업 템플릿</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<a class="reference internal image-reference" href="_images/2dclassgpu-1.png"><img alt="_images/2dclassgpu-1.png" class="align-center" src="_images/2dclassgpu-1.png" style="width: 793.0px; height: 756.0px;" /></a>
<a class="reference internal image-reference" href="_images/2dclassgpu-2.png"><img alt="_images/2dclassgpu-2.png" class="align-center" src="_images/2dclassgpu-2.png" style="width: 792.0px; height: 756.0px;" /></a>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="queue.html" class="btn btn-neutral float-left" title="Batch Queues" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="cisTEM.html" class="btn btn-neutral float-right" title="cisTEM" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019, GSDC.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>